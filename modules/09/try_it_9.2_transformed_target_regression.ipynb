{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try-it 9.2: Predicting Wages\n",
    "\n",
    "This activity is meant to summarize your work with regularized regression models.  You will use your earlier work with data preparation and pipelines together with what you've learned with grid searches to determine an optimal model.  In addition to the prior strategies, this example is an excellent opportunity to utilize the `TransformedTargetRegressor` estimator in scikitlearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "This dataset is loaded from the openml resource library.  Originally from census data, the data contains wage and demographic information on 534 individuals.  \n",
    "\n",
    "From the dataset documentation [here](https://www.openml.org/d/534):\n",
    "\n",
    "> The Current Population Survey (CPS) is used to supplement census information between census years. These data consist of a random sample of 534 persons from the CPS, with information on wages and other characteristics of the workers, including sex, number of years of education, years of work experience, occupational status, region of residence and union membership."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Build regression models to predict `WAGE`.  Incorporate the categorical features and transform the target using a logarithm.  Build `Ridge` models and consider some different amounts of regularization.  \n",
    "\n",
    "After fitting your model, interpret the model and try to understand what features led to higher wages.  Consider using `permutation_importance` that you encountered in module 8.  Discuss your findings in the class forum.\n",
    "\n",
    "For an in depth example discussing the perils of interpreting the coefficients see the example in scikitlearn examples [here](https://scikit-learn.org/stable/auto_examples/inspection/plot_linear_model_coefficient_interpretation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import (\n",
    "    make_column_transformer,\n",
    "    TransformedTargetRegressor,\n",
    "    make_column_selector,\n",
    ")\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "mpl.rcParams.update({\"axes.grid\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_openml(data_id=534, as_frame=True).frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query(\"WAGE > 1 and WAGE < 30\")  # snip 2 outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = \"WAGE\"\n",
    "numeric_features = df.columns[df.dtypes != \"category\"].to_list()\n",
    "numeric_features.remove(target_feature)\n",
    "one_hot_features = df.columns[df.dtypes == \"category\"].to_list()\n",
    "display([numeric_features, one_hot_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign to Feature and Target Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=target_feature)\n",
    "y = df[target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_pipe = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"scaler\",\n",
    "            make_column_transformer(\n",
    "                (\n",
    "                    StandardScaler(),\n",
    "                    numeric_features,\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "        (\"poly\", PolynomialFeatures(include_bias=False)),\n",
    "    ]\n",
    ").fit(X)\n",
    "\n",
    "display(poly_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(\n",
    "#     poly_pipe.transform(X), columns=poly_pipe.get_feature_names_out()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_pipe = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"ohe\",\n",
    "            make_column_transformer(\n",
    "                (\n",
    "                    OneHotEncoder(drop=\"if_binary\"),\n",
    "                    one_hot_features,\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ").fit(X)\n",
    "\n",
    "display(ohe_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(ohe_pipe.transform(X), columns=ohe_pipe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_union = FeatureUnion(\n",
    "    [\n",
    "        (\"poly_pipe\", poly_pipe),\n",
    "        (\"ohe_pipe\", ohe_pipe),\n",
    "    ]\n",
    ").fit(X)\n",
    "\n",
    "display(feature_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(\n",
    "#     feature_union.transform(X), columns=feature_union.get_feature_names_out()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipe = Pipeline(\n",
    "    [\n",
    "        (\"feature_union\", feature_union),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge\", Ridge(fit_intercept=True)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(ridge_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformed Target Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttr_pipe = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"ttr\",\n",
    "            TransformedTargetRegressor(\n",
    "                regressor=ridge_pipe, func=np.log, inverse_func=np.exp\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ").fit(X, y)\n",
    "\n",
    "ttr_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search over Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_inds, dev_inds) = train_test_split(\n",
    "    range(len(df)), random_state=42, train_size=0.75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_list = range(1, 4)\n",
    "alpha_list = 10 ** np.linspace(-5, 5, 51)\n",
    "param_grid = {\n",
    "    \"ttr__regressor__feature_union__poly_pipe__poly__degree\": degree_list,\n",
    "    \"ttr__regressor__ridge__alpha\": alpha_list,\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ttr_pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=[[train_inds, dev_inds]],\n",
    ").fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttr_pipe_best = grid_search.best_estimator_.fit(X, y)\n",
    "ttr_pipe_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of Model Error vs. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search.cv_results_[\"params\"]).join(\n",
    "    pd.DataFrame({\"mean_test_score\": grid_search.cv_results_[\"mean_test_score\"]})\n",
    ")\n",
    "\n",
    "results_df.columns = [name.split(\"__\")[-1] for name in results_df.columns]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_poly_degree = grid_search.best_params_[list(grid_search.best_params_.keys())[0]]\n",
    "best_alpha = grid_search.best_params_[list(grid_search.best_params_.keys())[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    results_df,\n",
    "    x=np.log10(1.0 / results_df[\"alpha\"]),\n",
    "    y=-results_df[\"mean_test_score\"],\n",
    "    labels={\n",
    "        \"x\": \"log10(1/alpha)\",\n",
    "        \"y\": \"MSE\",\n",
    "        \"degree\": \"Polynomial Degree\",\n",
    "    },\n",
    "    title=\"Model Performance vs. Ridge Alpha, Colored by Polynomial Degree<br>Best Alpha = %.2f, Best Poly Deg = %d\"\n",
    "    % (best_alpha, best_poly_degree),\n",
    "    color=\"degree\",\n",
    ")\n",
    "\n",
    "Image(fig.update_layout(title_x=0.5).to_image(format=\"png\", width=1200, scale=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter Plot of Predicted vs. Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ttr_pipe.predict(X)\n",
    "y_pred_best = ttr_pipe_best.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_basic = mean_squared_error(y, y_pred)  # was - 18.416299035907095\n",
    "mse_best = mean_squared_error(ttr_pipe_best.predict(X), y)\n",
    "[mse_basic, mse_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y,\n",
    "        y=y_pred,\n",
    "        mode=\"markers\",\n",
    "        name=\"Basic Pipeline, MSE = %.4f\" % mse_basic,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y,\n",
    "        y=y_pred_best,\n",
    "        mode=\"markers\",\n",
    "        name=\"Best Pipeline, MSE = %.4f\" % mse_best,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Prediction vs. Truth for Basic and Best Pipelines, Colored by Model Type\",\n",
    "    xaxis_title=\"Wage - Truth\",\n",
    "    yaxis_title=\"Wage - Predicted\",\n",
    ")\n",
    "\n",
    "Image(fig.update_layout(title_x=0.5).to_image(format=\"png\", width=1200, scale=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_permutation_importance_DataFrame(\n",
    "    model,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    permutation_importance_kwargs,\n",
    ") -> pd.DataFrame:\n",
    "    # Compute the importances\n",
    "    pi = permutation_importance(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        **permutation_importance_kwargs,\n",
    "    )\n",
    "\n",
    "    # Make frame from the importances, with columns arranged from\n",
    "    # lowest to highest mean importance\n",
    "    ordered_features = list(np.array(X.columns)[np.argsort(pi.importances_mean)])\n",
    "    return pd.DataFrame(pi.importances.T, columns=X.columns)[ordered_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance per feature\n",
    "df_pi = make_permutation_importance_DataFrame(\n",
    "    ttr_pipe_best,\n",
    "    X,\n",
    "    y,\n",
    "    {\"random_state\": 42, \"n_repeats\": 50},\n",
    ")\n",
    "\n",
    "df_pi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\n",
    "    px.bar(\n",
    "        data_frame=df_pi.mean() / df_pi.mean()[-1] * 100.0,\n",
    "        color=df_pi.std(),\n",
    "        orientation=\"h\",\n",
    "        title=\"Permutation Importance per Feature<br>Considering %d Shuffles per Feature\"\n",
    "        % len(df_pi),\n",
    "        labels={\n",
    "            \"value\": \"Permutation Importance, as a Percentage of %s Importance\"\n",
    "            % df_pi.columns[-1],\n",
    "            \"index\": \"Feature\",\n",
    "            \"color\": \"Standard Deviation\",\n",
    "        },\n",
    "    )\n",
    "    .update_layout(title_x=0.5)\n",
    "    .update_xaxes(tickvals=list(range(5, 105, 5)), range=[0, 100])\n",
    "    .to_image(format=\"png\", width=1200, scale=2)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
