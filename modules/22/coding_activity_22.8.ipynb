{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2b62eadd6388d0784ec50157af6895c",
     "grade": false,
     "grade_id": "cell-e339d70cd0649a8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Codio Activity 22.8: Hyperparameter Tuning with `keras`\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 40**\n",
    "\n",
    "This activity focuses on using hyperparameter tuning with the keras library.  There are two ways to perform a grid search with keras, and you will implement both. While `keras_tuner` was discussed in the lectures, here you will use the scikit-learn wrapper for keras where you can grid search the parameters using `GridSearchCV`.  You will implement this with the `KerasClassifier` to build some basic models on the wine dataset.  \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 13:51:43.141979: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-13 13:51:43.145351: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-13 13:51:43.154632: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-13 13:51:43.169456: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-13 13:51:43.173839: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-13 13:51:43.185640: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-13 13:51:44.097894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from tensorflow.keras.wrappers import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a80cd88ef50846b8916cabab07848ba",
     "grade": false,
     "grade_id": "cell-c00630cf57aecdf2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "Below, the wine dataset is loaded, split, and scaled.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.data\n",
    "y = to_categorical(wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "386b539c47e2b39f58f930baac434187",
     "grade": false,
     "grade_id": "cell-7318f421fe13c40e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### The Build Function\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To use the `KerasClassifier` you first need to write a function that creates a keras model and takes in arguments for the parameters you wish to search. Below is a very basic example.  Note that rather than \n",
    "\n",
    "```python\n",
    "def build_function(neurons = 1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation = 'relu'))\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    model.compile(...)\n",
    "    return model\n",
    "```\n",
    "\n",
    "Complete the `build_function` below with appropriate arguments for `model.compile()`.\n",
    "\n",
    "After you are done, call the function `build_function` with argument `neurons = 100` and assign it to the variable `ans`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da90d2e6efec19252565daa9350aa3c5",
     "grade": false,
     "grade_id": "cell-a2bce77d17112fd1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential, built=False>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def build_function(neurons=1):\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            Dense(neurons, activation=\"relu\"),\n",
    "            Dense(3, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "ans = build_function(neurons=100)\n",
    "\n",
    "### ANSWER CHECK\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15d6ecc24a01f4636e8c6bc55418ca09",
     "grade": false,
     "grade_id": "cell-2fb545190eb4b55d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Creating the `KerasClassifier`\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, use the `build_function` to instantiate the `KerasClassifier` as `model` with `epochs = 10`. Fit the model on the data `X_scaled` and `y`, and assign the accuracy as `score_1` below.  Note that this will use 1 node as defaulted in the `build_function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67a7dcf0e80efbc40611c1783daa6246",
     "grade": false,
     "grade_id": "cell-0275116e4f507015",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sequential model 'sequential_3' has no defined outputs yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mset_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39mbuild_function, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m score_1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(X_scaled, y)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m### ANSWER CHECK\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/scikeras/wrappers.py:1501\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[1;32m   1500\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m-> 1501\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/scikeras/wrappers.py:770\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m    767\u001b[0m )\n\u001b[1;32m    768\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/scikeras/wrappers.py:936\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_encoder_\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[1;32m    934\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m--> 936\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_model_compatibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_keras_model(\n\u001b[1;32m    939\u001b[0m     X,\n\u001b[1;32m    940\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    946\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/scikeras/wrappers.py:559\u001b[0m, in \u001b[0;36mBaseWrapper._check_model_compatibility\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;66;03m# check if this is a multi-output model\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_outputs_expected_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;66;03m# n_outputs_expected_ is generated by data transformers\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;66;03m# we recognize the attribute but do not force it to be\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;66;03m# generated\u001b[39;00m\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_expected_ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m):\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    561\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected a Keras model input of size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    562\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_expected_\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39moutputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         )\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# check that if the user gave us a loss function it ended up in\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# the actual model\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/site-packages/keras/src/models/sequential.py:292\u001b[0m, in \u001b[0;36mSequential.outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_functional:\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_functional\u001b[38;5;241m.\u001b[39moutputs\n\u001b[0;32m--> 292\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequential model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no defined outputs yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Sequential model 'sequential_3' has no defined outputs yet."
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "model = KerasClassifier(build_fn=build_function, epochs=10)\n",
    "model.fit(X_scaled, y)\n",
    "score_1 = model.score(X_scaled, y)\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model.score(X_scaled, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df011bea7a42d30ece3fb8b0344dc798",
     "grade": false,
     "grade_id": "cell-d3d9e1ce9a8751ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Performing the Grid Search\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, to perform a grid search you just need to create a dictionary with the hyperparameter named `neurons = [10, 50, 100]`.  Use `GridSearchCV` with the model and appropriate hyperparameter dictionary to fit the data.  \n",
    "\n",
    "```python\n",
    "ann_grid = GridSearchCV(model, param_grid = params)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b673e7130b5dc921a8f13a1bee117b95",
     "grade": false,
     "grade_id": "cell-8c00e8a1dee417d8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x79a02447ea90>,\n",
       "             param_grid={'neurons': [10, 50, 100]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "params = {\"neurons\": [10, 50, 100]}\n",
    "ann_grid = GridSearchCV(model, param_grid=params)\n",
    "\n",
    "### ANSWER CHECK\n",
    "ann_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c514c910a3141fc8c1bc56092bbf48e4",
     "grade": false,
     "grade_id": "cell-960b42fedb69b7e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Fit and Evaluate the model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, fit and evaluate the model.  Assign your score to `grid_score` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e33b5417c6dbb816bfba94cc8f64a5df",
     "grade": false,
     "grade_id": "cell-f8e6edb517c71335",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 1.3423 - accuracy: 0.2676\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2428 - accuracy: 0.3169\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1762 - accuracy: 0.3451\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1189 - accuracy: 0.3521\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0706 - accuracy: 0.4155\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0246 - accuracy: 0.4366\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9796 - accuracy: 0.4648\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9384 - accuracy: 0.4930\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8985 - accuracy: 0.5352\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8611 - accuracy: 0.5563\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7237 - accuracy: 0.8611\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1802 - accuracy: 0.4507\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1011 - accuracy: 0.4930\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0487 - accuracy: 0.5211\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0035 - accuracy: 0.5563\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9633 - accuracy: 0.5775\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9251 - accuracy: 0.5845\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8885 - accuracy: 0.5986\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8544 - accuracy: 0.6197\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8221 - accuracy: 0.6338\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7896 - accuracy: 0.6338\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9066 - accuracy: 0.6944\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1861 - accuracy: 0.4930\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0825 - accuracy: 0.5282\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0154 - accuracy: 0.5423\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9621 - accuracy: 0.5563\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9153 - accuracy: 0.5563\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8715 - accuracy: 0.5775\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8286 - accuracy: 0.6127\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7898 - accuracy: 0.6127\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7543 - accuracy: 0.6268\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7221 - accuracy: 0.6408\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9515 - accuracy: 0.5833\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2472 - accuracy: 0.2867\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1631 - accuracy: 0.3217\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1109 - accuracy: 0.3427\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0668 - accuracy: 0.3776\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0285 - accuracy: 0.4056\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9931 - accuracy: 0.4755\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9602 - accuracy: 0.5105\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9309 - accuracy: 0.5524\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9033 - accuracy: 0.5874\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8749 - accuracy: 0.5944\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1228 - accuracy: 0.4571\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 1.1498 - accuracy: 0.3566\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0862 - accuracy: 0.4056\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0442 - accuracy: 0.4545\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0090 - accuracy: 0.4895\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9772 - accuracy: 0.5035\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9480 - accuracy: 0.5524\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9187 - accuracy: 0.5734\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8907 - accuracy: 0.6224\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8641 - accuracy: 0.6503\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8387 - accuracy: 0.6643\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.8571\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0625 - accuracy: 0.4437\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8476 - accuracy: 0.7042\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7288 - accuracy: 0.8028\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.8451\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.8803\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.9225\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.9366\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.9507\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.9577\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.9577\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.7778\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 1.1047 - accuracy: 0.4577\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9129 - accuracy: 0.6268\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8002 - accuracy: 0.7183\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7117 - accuracy: 0.7746\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.7958\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.8451\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.8662\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8944\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.9296\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.9437\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.8889\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0410 - accuracy: 0.4577\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8099 - accuracy: 0.7324\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.8451\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.8944\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.9155\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9296\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.9366\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.9366\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.9507\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.9648\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.7222\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 1.0159 - accuracy: 0.5175\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8317 - accuracy: 0.6783\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7194 - accuracy: 0.7622\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.8392\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.8741\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.8951\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.9231\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.9441\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.9510\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.9790\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8857\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1799 - accuracy: 0.2727\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9753 - accuracy: 0.5524\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8538 - accuracy: 0.6923\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7626 - accuracy: 0.7413\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.7762\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.8392\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.8601\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8741\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8951\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.9161\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.9714\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0117 - accuracy: 0.4930\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7503 - accuracy: 0.8451\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.9366\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.9437\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.9507\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.9648\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.9718\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.9789\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.9789\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9789\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8611\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9757 - accuracy: 0.5493\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7282 - accuracy: 0.8662\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.9155\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.9296\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.9366\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.9507\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.9577\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.9718\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9718\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9789\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8889\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9933 - accuracy: 0.5493\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7222 - accuracy: 0.7887\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.8521\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8803\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8944\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.9155\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.9225\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.9577\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.9507\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9789\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.8611\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 1.0778 - accuracy: 0.3846\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7659 - accuracy: 0.8322\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.9650\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.9790\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.9720\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.9790\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.9860\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2613 - accuracy: 0.9860\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9860\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9860\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.5245\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7797 - accuracy: 0.8601\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.9301\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.9441\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.9650\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.9720\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.9720\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.9720\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.9720\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.9860\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.9429\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 2ms/step - loss: 0.8325 - accuracy: 0.7472\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.9382\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.9663\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.9831\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.9831\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.9831\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9831\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9831\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9831\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9888\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9888\n",
      "0.9887640476226807\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "ann_grid.fit(X_scaled, y)\n",
    "grid_score = ann_grid.score(X_scaled, y)\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(grid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6296e6782e4667f383aa00b46f2a2a98",
     "grade": false,
     "grade_id": "cell-c15487b1ec27581b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Because of the grading enviornment, a more exhaustive search over additional parameters is not an option.  To extend the work here should be straightforward enough, and this is a nice solution to grid searching the hyperparameters of a model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
