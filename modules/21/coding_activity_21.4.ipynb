{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6dfe9b60495ef30844e3ae0c17c4ea61",
     "grade": false,
     "grade_id": "cell-8e6724797402a4be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Codio Activity 21.4: Implementing Bagging\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 50**\n",
    "\n",
    "This activity focuses on using the `BaggingClassifier`.  You will use the scikit-learn implementation to compare performance on the fetal health dataset to that of the other models in the module -- Random Forests, Adaptive Boosting, and Gradient Boosting. The `BaggingClassifier` is a meta estimator that will aggregate estimators built on samples of the data.  You are to specify certain estimators and samples to become familiar with the functionality of the estimator and the variations you can produce with important arguments.  \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb2ab40c24dd1dd67ed6da1176865b5b",
     "grade": false,
     "grade_id": "cell-c49cddcd44fd7d4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Data and Documentation\n",
    "\n",
    "Below the data is loaded and prepared.  For this exercise, you will be expected to consult the documentation on the `BaggingClassifier` [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator).  The vocabulary in each problem can be found in the documentation and you are expected to use the correct settings for the arguments as a result of reading the documentation.  For each model, be sure to set `random_state = 42`.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/fetal.zip\", compression=\"zip\")\n",
    "X, y = df.drop(\"fetal_health\", axis=1), df[\"fetal_health\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a44331c04f39d0a30c9945d11c49e54b",
     "grade": false,
     "grade_id": "cell-e4a9290546050a63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Aggregating bootstrap models\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To start, create an ensemble of `DecisionTreeClassifier` classifiers built on bootstrap samples of the data. Remember to set the `random_state = 42`.  *This is equivalent to the default model for `BaggingClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab94aaca430883b5cd5a811bc4586103",
     "grade": false,
     "grade_id": "cell-c19eb5f000426b4d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9511278195488722\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "bagged_model = BaggingClassifier(DecisionTreeClassifier(), random_state=42).fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "bagged_score = bagged_model.score(X_test, y_test)\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(bagged_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1deae4fecbe28184a8b949cc29d3c279",
     "grade": false,
     "grade_id": "cell-f36f23cde3504a9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Pasting vs. Bagging\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Consult the documentation [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) and adjust the appropriate argument to change from **bagging** to **pasting**.  Create your model as `pasted_model` and score on the test data as `pasted_score`.  Be sure to set `random_state = 42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7ce3ea230c9c239ea5c02fa288ac6ec",
     "grade": false,
     "grade_id": "cell-ead12c3abd052f0f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9379699248120301\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "pasted_model = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), random_state=42, bootstrap=False\n",
    ").fit(X_train, y_train)\n",
    "pasted_score = pasted_model.score(X_test, y_test)\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(pasted_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f0005a69ebf27371fb4cc442f2d264d",
     "grade": false,
     "grade_id": "cell-9e658a1750560496",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Random Subspaces\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Consult the documentation [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) and adjust the appropriate argument to change from **bagging** to **random subspaces** with at most 10 features sampled.  Train this on the training data and score it on the test data. Create your model as `random_subspace` and score as `subspace_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1be9f668722271a8f9f5e0fba9f883ae",
     "grade": false,
     "grade_id": "cell-dca845cff278bad8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943609022556391\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "subspace_model = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), random_state=42, bootstrap=False, max_features=10\n",
    ").fit(X_train, y_train)\n",
    "subspace_score = subspace_model.score(X_test, y_test)\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(subspace_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0f50e6aa4fd92821da8740e034692d9",
     "grade": false,
     "grade_id": "cell-03e0faf6fb6f14b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Random Patches\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Consult the documentation [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) and adjust the appropriate argument to change from **bagging** to **random patches**. Use no more than 30% of the data and no more than 10 features in your samples.  Train this on the training data and score it on the test data as `patches_model` and `patches_score` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23b7b207fdec7b2819d082ea8b3e6f42",
     "grade": false,
     "grade_id": "cell-4a70c410a6884470",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9304511278195489\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "patches_model = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),\n",
    "    random_state=42,\n",
    "    bootstrap=False,\n",
    "    max_samples=0.3,\n",
    "    max_features=10,\n",
    ").fit(X_train, y_train)\n",
    "patches_score = patches_model.score(X_test, y_test)\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(patches_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "882e32b2b9f7d12c30b1586023cba551",
     "grade": false,
     "grade_id": "cell-6763bbf860939634",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Nature of the Tree Models\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Consult the documentation [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) and observe whether or not bagging typically works with simple or complex tree models.  Enter your answer as `simple` or `complex` as a string to `ans5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70517302de79e8b3923e273f721fe0d3",
     "grade": false,
     "grade_id": "cell-557f28e1d6225695",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "ans5 = \"complex\"\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(ans5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
