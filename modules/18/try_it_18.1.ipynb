{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models and Vectorization Strategies for Text Classification\n",
    "\n",
    "This try-it focuses on weighing the positives and negatives of different estimators and vectorization strategies for a text classification problem.  In order to consider each of these components, you should make use of the `Pipeline` and `GridSearchCV` objects in scikitlearn to try different combinations of vectorizers with different estimators.  For each of these, you also want to use the `.cv_results_` to examine the time for the estimator to fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "The dataset below is from [kaggle]() and contains a dataset named the \"ColBert Dataset\" created for this [paper](https://arxiv.org/pdf/2004.12765.pdf).  You are to use the text column to classify whether or not the text was humorous.  It is loaded and displayed below.\n",
    "\n",
    "**Note:** The original dataset contains 200K rows of data. It is best to try to use the full dtaset. If the original dataset is too large for your computer, please use the 'dataset-minimal.csv', which has been reduced to 100K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/dataset-minimal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you call a turtle without its shell? d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 reasons the 2016 election feels so personal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pasco police shot mexican migrant from behind,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  humor\n",
       "0  Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
       "1  Watch: darvish gave hitter whiplash with slow ...  False\n",
       "2  What do you call a turtle without its shell? d...   True\n",
       "3      5 reasons the 2016 election feels so personal  False\n",
       "4  Pasco police shot mexican migrant from behind,...  False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humor\n",
       "False    0.500215\n",
       "True     0.499785\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"humor\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task\n",
    "\n",
    "\n",
    "**Text preprocessing:** As a pre-processing step, perform both `stemming` and `lemmatizing` to normalize your text before classifying. For each technique use both the `CountVectorize`r and `TfidifVectorizer` and use options for stop words and max features to prepare the text data for your estimator.\n",
    "\n",
    "**Classification:** Once you have prepared the text data with stemming lemmatizing techniques, consider `LogisticRegression`, `DecisionTreeClassifier`, and `MultinomialNB` as classification algorithms for the data. Compare their performance in terms of accuracy and speed.\n",
    "\n",
    "Share the results of your best classifier in the form of a table with the best version of each estimator, a dictionary of the best parameters and the best score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = X.apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "Xs = Xt.apply(lambda x: [stemmer.stem(xk) for xk in x]).apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "Xl = Xt.apply(lambda x: [lemma.lemmatize(xk) for xk in x]).apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"humor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(vectorizer_name: str, classifier_name: str):\n",
    "    return Pipeline(\n",
    "        [\n",
    "            (\"vectorizer\", eval(vectorizer_name)()),\n",
    "            (\"classifier\", eval(classifier_name)()),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessors = [\"none\", \"stemmer\", \"lemmatizer\"]\n",
    "vectorizers = [\"CountVectorizer\", \"TfidfVectorizer\"]\n",
    "classifiers = [\"LogisticRegression\", \"DecisionTreeClassifier\", \"MultinomialNB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_param_grids = {\n",
    "    \"CountVectorizer\": {\n",
    "        \"vectorizer__stop_words\": [None, \"english\"],\n",
    "    },\n",
    "    \"TfidfVectorizer\": {\n",
    "        \"vectorizer__stop_words\": [None, \"english\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running preprocessor = none, vectorizer = CountVectorizer, and classifier = LogisticRegression\n",
      "Running preprocessor = none, vectorizer = CountVectorizer, and classifier = DecisionTreeClassifier\n",
      "Running preprocessor = none, vectorizer = CountVectorizer, and classifier = MultinomialNB\n",
      "Running preprocessor = none, vectorizer = TfidfVectorizer, and classifier = LogisticRegression\n",
      "Running preprocessor = none, vectorizer = TfidfVectorizer, and classifier = DecisionTreeClassifier\n",
      "Running preprocessor = none, vectorizer = TfidfVectorizer, and classifier = MultinomialNB\n",
      "Running preprocessor = stemmer, vectorizer = CountVectorizer, and classifier = LogisticRegression\n",
      "Running preprocessor = stemmer, vectorizer = CountVectorizer, and classifier = DecisionTreeClassifier\n",
      "Running preprocessor = stemmer, vectorizer = CountVectorizer, and classifier = MultinomialNB\n",
      "Running preprocessor = stemmer, vectorizer = TfidfVectorizer, and classifier = LogisticRegression\n",
      "Running preprocessor = stemmer, vectorizer = TfidfVectorizer, and classifier = DecisionTreeClassifier\n",
      "Running preprocessor = stemmer, vectorizer = TfidfVectorizer, and classifier = MultinomialNB\n",
      "Running preprocessor = lemmatizer, vectorizer = CountVectorizer, and classifier = LogisticRegression\n",
      "Running preprocessor = lemmatizer, vectorizer = CountVectorizer, and classifier = DecisionTreeClassifier\n",
      "Running preprocessor = lemmatizer, vectorizer = CountVectorizer, and classifier = MultinomialNB\n",
      "Running preprocessor = lemmatizer, vectorizer = TfidfVectorizer, and classifier = LogisticRegression\n",
      "Running preprocessor = lemmatizer, vectorizer = TfidfVectorizer, and classifier = DecisionTreeClassifier\n",
      "Running preprocessor = lemmatizer, vectorizer = TfidfVectorizer, and classifier = MultinomialNB\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "for preprocessor in preprocessors:\n",
    "    if preprocessor == \"none\":\n",
    "        Xp = X\n",
    "    elif preprocessor == \"stemmer\":\n",
    "        Xp = Xs\n",
    "    elif preprocessor == \"lemmatizer\":\n",
    "        Xp = Xl\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid choice '{preprocessor}' for preprocessor\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        Xp, y, random_state=42, test_size=0.25\n",
    "    )\n",
    "\n",
    "    for vectorizer in vectorizers:\n",
    "        for classifier in classifiers:\n",
    "            print(\n",
    "                f\"Running preprocessor = {preprocessor}, vectorizer = {vectorizer}, and classifier = {classifier}\"\n",
    "            )\n",
    "            tic = time()\n",
    "            grid = GridSearchCV(\n",
    "                estimator=make_pipeline(\n",
    "                    vectorizer_name=vectorizer, classifier_name=classifier\n",
    "                ),\n",
    "                param_grid=all_param_grids[vectorizer],\n",
    "            ).fit(X_train, y_train)\n",
    "            grid_search_time = time() - tic\n",
    "            results_list.append(\n",
    "                {\n",
    "                    \"preprocessor\": preprocessor,\n",
    "                    \"vectorizer\": vectorizer,\n",
    "                    \"classifier\": classifier,\n",
    "                    \"average fit time\": grid_search_time\n",
    "                    / len(grid.cv_results_[\"params\"]),\n",
    "                    \"best score\": grid.best_estimator_.score(X_test, y_test),\n",
    "                    \"best params\": grid.best_params_,\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessor</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>average fit time</th>\n",
       "      <th>best score</th>\n",
       "      <th>best params</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>none</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>12.796625</td>\n",
       "      <td>0.92400</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>lemmatizer</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>11.746000</td>\n",
       "      <td>0.92340</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>stemmer</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>10.387622</td>\n",
       "      <td>0.92064</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>none</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>7.085414</td>\n",
       "      <td>0.91676</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>lemmatizer</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>7.762917</td>\n",
       "      <td>0.91348</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>none</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>3.961107</td>\n",
       "      <td>0.91276</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>stemmer</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>7.584452</td>\n",
       "      <td>0.91132</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>lemmatizer</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>3.987883</td>\n",
       "      <td>0.91004</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>none</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>4.115337</td>\n",
       "      <td>0.90980</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>stemmer</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>3.881893</td>\n",
       "      <td>0.90848</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>lemmatizer</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>4.022611</td>\n",
       "      <td>0.90752</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>stemmer</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>3.983942</td>\n",
       "      <td>0.90488</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>none</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>80.141117</td>\n",
       "      <td>0.86324</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>lemmatizer</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>74.781501</td>\n",
       "      <td>0.86276</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>stemmer</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>69.134362</td>\n",
       "      <td>0.86100</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>lemmatizer</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>132.554633</td>\n",
       "      <td>0.85276</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>stemmer</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>124.973663</td>\n",
       "      <td>0.85208</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>none</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>133.033051</td>\n",
       "      <td>0.85028</td>\n",
       "      <td>{'vectorizer__stop_words': None}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       preprocessor       vectorizer  average fit time  \\\n",
       "classifier                                                               \n",
       "LogisticRegression             none  CountVectorizer         12.796625   \n",
       "LogisticRegression       lemmatizer  CountVectorizer         11.746000   \n",
       "LogisticRegression          stemmer  CountVectorizer         10.387622   \n",
       "LogisticRegression             none  TfidfVectorizer          7.085414   \n",
       "LogisticRegression       lemmatizer  TfidfVectorizer          7.762917   \n",
       "MultinomialNB                  none  CountVectorizer          3.961107   \n",
       "LogisticRegression          stemmer  TfidfVectorizer          7.584452   \n",
       "MultinomialNB            lemmatizer  CountVectorizer          3.987883   \n",
       "MultinomialNB                  none  TfidfVectorizer          4.115337   \n",
       "MultinomialNB               stemmer  CountVectorizer          3.881893   \n",
       "MultinomialNB            lemmatizer  TfidfVectorizer          4.022611   \n",
       "MultinomialNB               stemmer  TfidfVectorizer          3.983942   \n",
       "DecisionTreeClassifier         none  CountVectorizer         80.141117   \n",
       "DecisionTreeClassifier   lemmatizer  CountVectorizer         74.781501   \n",
       "DecisionTreeClassifier      stemmer  CountVectorizer         69.134362   \n",
       "DecisionTreeClassifier   lemmatizer  TfidfVectorizer        132.554633   \n",
       "DecisionTreeClassifier      stemmer  TfidfVectorizer        124.973663   \n",
       "DecisionTreeClassifier         none  TfidfVectorizer        133.033051   \n",
       "\n",
       "                        best score                       best params  \n",
       "classifier                                                            \n",
       "LogisticRegression         0.92400  {'vectorizer__stop_words': None}  \n",
       "LogisticRegression         0.92340  {'vectorizer__stop_words': None}  \n",
       "LogisticRegression         0.92064  {'vectorizer__stop_words': None}  \n",
       "LogisticRegression         0.91676  {'vectorizer__stop_words': None}  \n",
       "LogisticRegression         0.91348  {'vectorizer__stop_words': None}  \n",
       "MultinomialNB              0.91276  {'vectorizer__stop_words': None}  \n",
       "LogisticRegression         0.91132  {'vectorizer__stop_words': None}  \n",
       "MultinomialNB              0.91004  {'vectorizer__stop_words': None}  \n",
       "MultinomialNB              0.90980  {'vectorizer__stop_words': None}  \n",
       "MultinomialNB              0.90848  {'vectorizer__stop_words': None}  \n",
       "MultinomialNB              0.90752  {'vectorizer__stop_words': None}  \n",
       "MultinomialNB              0.90488  {'vectorizer__stop_words': None}  \n",
       "DecisionTreeClassifier     0.86324  {'vectorizer__stop_words': None}  \n",
       "DecisionTreeClassifier     0.86276  {'vectorizer__stop_words': None}  \n",
       "DecisionTreeClassifier     0.86100  {'vectorizer__stop_words': None}  \n",
       "DecisionTreeClassifier     0.85276  {'vectorizer__stop_words': None}  \n",
       "DecisionTreeClassifier     0.85208  {'vectorizer__stop_words': None}  \n",
       "DecisionTreeClassifier     0.85028  {'vectorizer__stop_words': None}  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_list).set_index(\"classifier\").sort_values(\n",
    "    by=\"best score\", ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully standalone snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.91276, 0.91276]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df = pd.read_csv(\"./data/dataset-minimal.csv\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"humor\"], random_state=42\n",
    ")\n",
    "\n",
    "# All defaults\n",
    "estimator = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", CountVectorizer()),\n",
    "        (\"classifier\", MultinomialNB()),\n",
    "    ]\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "acc_all_default = estimator.score(X_test, y_test)\n",
    "\n",
    "# Grid over a single parameter - stop words, no stop words\n",
    "grid = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid={\n",
    "        \"vectorizer__stop_words\": [None, \"english\"],\n",
    "    },\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "acc_grid = grid.best_estimator_.score(X_test, y_test)\n",
    "\n",
    "[\n",
    "    acc_all_default,\n",
    "    acc_grid,\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
