{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Customer Segmentation\n",
    "\n",
    "In this activity, you are tasked with profiling customer groups for a large telecommunications company.  The data provided contains information on customers purchasing and useage behavior with the telecom products.  Your goal is to use PCA and clustering to segment these customers into meaningful groups, and report back your findings.  \n",
    "\n",
    "Because these results need to be interpretable, it is important to keep the number of clusters reasonable.  Think about how you might represent some of the non-numeric features so that they can be included in your segmentation models.  You are to report back your approach and findings to the class.  Be specific about what features were used and how you interpret the resulting clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import itertools\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "mpl.rcParams.update({\"axes.grid\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load and Initial Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = pd.read_csv(\"./data/telco_churn_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Columns to Toss\n",
    "\n",
    "For one reason or another we want to toss these ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns have many nulls\n",
    "drop_columns = df_in.loc[\n",
    "    :, df_in.isnull().sum() / df_in.isnull().count() * 100.0 > 10.0\n",
    "].columns.to_list()\n",
    "\n",
    "display(drop_columns)\n",
    "\n",
    "# These columns are representations of other columns or otherwise unneeded\n",
    "drop_columns += [\n",
    "    \"Under 30\",\n",
    "    \"Senior Citizen\",\n",
    "    \"Dependents\",\n",
    "    \"City\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Population\",\n",
    "    \"Customer ID\",\n",
    "]\n",
    "\n",
    "display(drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various Columns That Are Functions of Other Columns\n",
    "\n",
    "Can we (should we) remove these multiplicative products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that total total long distance is average long distance x num months\n",
    "if 0:\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Actual\": df_in[\"Total Long Distance Charges\"],\n",
    "                \"Assertion\": df_in[\"Avg Monthly Long Distance Charges\"]\n",
    "                * df_in[\"Tenure in Months\"],\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns.append(\"Avg Monthly Long Distance Charges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that monthly charge approximately equals average total regular charges\n",
    "if 0:\n",
    "    plt.scatter(\n",
    "        df_in[\"Monthly Charge\"],\n",
    "        df_in[\"Total Regular Charges\"] / df_in[\"Tenure in Months\"],\n",
    "        color=\"blue\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns.append(\"Monthly Charge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that total extra data charges is proportional to Total GB Download when unlimited data is false\n",
    "df_in[\"Total GB Download\"] = (\n",
    "    df_in[\"Avg Monthly GB Download\"] * df_in[\"Tenure in Months\"]\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    df_in[\"Total GB Download\"],\n",
    "    df_in[\"Total Extra Data Charges\"],\n",
    "    c=df_in[\"Unlimited Data\"] == \"Yes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns.append(\"Avg Monthly GB Download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How meaningful are the other total charges columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_str_to_idx(series: pd.Series) -> pd.Series:\n",
    "    if series.dtype == \"object\" and series.nunique() <= 5 and 0:\n",
    "        return pd.Series(np.unique(series, return_inverse=True)[1])\n",
    "    return series\n",
    "\n",
    "\n",
    "df = df_in.drop(columns=drop_columns).apply(cat_str_to_idx)\n",
    "assert np.all(df.isnull().sum() == 0), \"Some Nulls Remain\"\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Numeric Columns\n",
    "\n",
    "Those columns where data type is not object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df[df.columns[df.dtypes != \"object\"]]\n",
    "df_numeric[\"Unlimited Data\"] = df_in[\"Unlimited Data\"] == \"Yes\"\n",
    "df_numeric = df_numeric.drop(columns=[\"Avg Monthly GB Download\"])\n",
    "display(df_numeric.head())\n",
    "display(df_numeric.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = (df_numeric - df_numeric.mean()) / df_numeric.std()\n",
    "display(df_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EV vs. Chosen Columns Analysis\n",
    "\n",
    "Looking for Combinations with High Cumulative EV With 3 Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Allowable Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = list(range(df_numeric.shape[1]))\n",
    "choosek = 5\n",
    "combos = list(itertools.combinations(inds, choosek))\n",
    "print(\n",
    "    \"Checking %d of combinations of choosing %d from %d\"\n",
    "    % (len(combos), choosek, len(inds))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative EV vs. Num Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_ev_3_combos = []\n",
    "ncomp = 3\n",
    "\n",
    "for m in range(len(combos)):\n",
    "    combo = list(combos[m])\n",
    "    cum_ev = (\n",
    "        PCA(n_components=choosek, random_state=123)\n",
    "        .fit(df_scaled.iloc[:, combo])\n",
    "        .explained_variance_ratio_\n",
    "        * 100.0\n",
    "    ).cumsum()\n",
    "\n",
    "    cum_ev_3_combos.append(cum_ev[ncomp - 1])\n",
    "    if m % 1000 == 0:\n",
    "        display([m, combo, cum_ev_3_combos[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Cumulative EV at 3 Components vs. Combination Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_inds = np.argsort(cum_ev_3_combos)[::-1]\n",
    "plt.scatter(range(len(combos)), np.array(cum_ev_3_combos)[sorted_inds], color=\"blue\")\n",
    "\n",
    "for ind in range(5):\n",
    "    m = sorted_inds[ind]\n",
    "    combo = list(combos[m])\n",
    "    combo_columns = df_scaled.columns[combo]\n",
    "    display([m, cum_ev_3_combos[m], combo_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the Top Combination\n",
    "\n",
    "The one with the highest EV @ 3 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df_scaled.iloc[:, list(combos[sorted_inds[0]])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Cumulative EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = (\n",
    "    PCA(n_components=df_scaled.shape[1], random_state=123)\n",
    "    .fit(df_scaled)\n",
    "    .explained_variance_ratio_\n",
    "    * 100.0\n",
    ")\n",
    "cum_ev = ev.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1_color = \"black\"\n",
    "ax1.plot(\n",
    "    np.arange(len(ev)) + 1,\n",
    "    ev,\n",
    "    linestyle=\"solid\",\n",
    "    marker=\"o\",\n",
    "    color=ax1_color,\n",
    ")\n",
    "\n",
    "ax1.set_xlabel(\"Number of Components\")\n",
    "ax1.set_ylabel(\"Explained Variance Ratio (%)\", color=ax1_color)\n",
    "\n",
    "ax2_color = \"blue\"\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(\n",
    "    np.arange(len(cum_ev)) + 1,\n",
    "    cum_ev,\n",
    "    linestyle=\"solid\",\n",
    "    marker=\"o\",\n",
    "    color=ax2_color,\n",
    ")\n",
    "\n",
    "ax2.set_ylabel(\"Cumulative Variance Explained (%)\", color=ax2_color)\n",
    "ax2.tick_params(axis=\"y\", labelcolor=ax2_color)\n",
    "\n",
    "\n",
    "def crosshairs_at(\n",
    "    target_cev: float = 0.0, ncomp: int = None, color: str = \"\", linestyle: str = \"--\"\n",
    "):\n",
    "    if ncomp is None:\n",
    "        ncomp = PCA(n_components=target_cev / 100.0).fit(df_scaled).n_components_\n",
    "\n",
    "    label = \"%2d Components -> %.2f%% Variance\" % (ncomp, cum_ev[ncomp - 1])\n",
    "    ax2.axhline(cum_ev[ncomp - 1], color=color, linestyle=linestyle)\n",
    "    ax2.axvline(ncomp, label=label, color=color, linestyle=linestyle)\n",
    "\n",
    "\n",
    "crosshairs_at(ncomp=2, color=\"red\")\n",
    "crosshairs_at(ncomp=3, color=\"cyan\")\n",
    "crosshairs_at(ncomp=4, color=\"magenta\")\n",
    "# crosshairs_at(target_cev=95.0, color=\"blue\")\n",
    "\n",
    "plt.setp(plt.legend(loc=\"center right\", fancybox=True).texts, family=\"monospace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit\n",
    "\n",
    "For simplicity just go with 3 components for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3\n",
    "X = PCA(n_components=3, random_state=123).fit_transform(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search Over Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_list = np.arange(2, 8)\n",
    "display(n_clusters_list)\n",
    "inertia = []\n",
    "\n",
    "for n_clusters in n_clusters_list:\n",
    "    kmeans = cluster.KMeans(n_clusters=n_clusters, random_state=123).fit(X)\n",
    "    (_, counts) = np.unique(kmeans.labels_, return_counts=True)\n",
    "    display([n_clusters, kmeans.inertia_, counts])\n",
    "    inertia.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Inertia vs. Num Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Inertia vs. Num Clusters\n",
    "ax1_color = \"black\"\n",
    "ax1.plot(\n",
    "    n_clusters_list,\n",
    "    inertia,\n",
    "    linestyle=\"solid\",\n",
    "    marker=\"o\",\n",
    "    color=ax1_color,\n",
    ")\n",
    "\n",
    "ax1.set_xlabel(\"Number of Clusters\")\n",
    "ax1.set_ylabel(\"Inertia\")\n",
    "\n",
    "# Differential Inertia vs. Num Clusters\n",
    "ax2_color = \"blue\"\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(\n",
    "    n_clusters_list[:-1],\n",
    "    np.diff(inertia),\n",
    "    linestyle=\"solid\",\n",
    "    marker=\"o\",\n",
    "    color=ax2_color,\n",
    ")\n",
    "\n",
    "ax2.set_ylabel(\"Differential Inertia\", color=ax2_color)\n",
    "ax2.tick_params(axis=\"y\", labelcolor=ax2_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "5 clusters is good enough, after that the improvement decelerates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=5, random_state=123).fit(X)\n",
    "\n",
    "(unique_labels, counts) = np.unique(kmeans.labels_, return_counts=True)\n",
    "display([unique_labels, counts, kmeans.inertia_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = pd.DataFrame(\n",
    "    X, columns=[\"Component\" + str(k + 1) for k in range(X.shape[1])]\n",
    ").join(pd.DataFrame({\"kmeans\": kmeans.labels_}))\n",
    "display(df_labeled.head())\n",
    "display(df_labeled.groupby(\"kmeans\").count().reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_scatter_3d(\n",
    "    data_frame: pd.DataFrame = None,\n",
    "    color: str = None,\n",
    "):\n",
    "    px.scatter_3d(\n",
    "        data_frame=data_frame,\n",
    "        x=data_frame.columns[0],\n",
    "        y=data_frame.columns[1],\n",
    "        z=data_frame.columns[2],\n",
    "        color=color,\n",
    "    ).update_layout(autosize=False, width=600, height=600).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scatter_3d(df_labeled, color=\"kmeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=n_components)\n",
    "fig.set_size_inches((14, 6))\n",
    "\n",
    "for k in range(n_components):\n",
    "    sns.kdeplot(\n",
    "        df_labeled,\n",
    "        x=df_labeled.columns[k],\n",
    "        fill=True,\n",
    "        hue=\"kmeans\",\n",
    "        ax=ax[k],\n",
    "        palette=\"bright\",\n",
    "        alpha=0.5,\n",
    "        linewidth=1,\n",
    "    )\n",
    "\n",
    "fig.suptitle(\"Density vs. Component Axis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Search\n",
    "\n",
    "Search over range of eps and min samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Distance Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = 75\n",
    "distances = np.sort(\n",
    "    np.mean(\n",
    "        NearestNeighbors(n_neighbors=min_samples, algorithm=\"auto\")\n",
    "        .fit(X)\n",
    "        .kneighbors(X)[0],\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_size_inches((14, 8))\n",
    "\n",
    "\n",
    "ax[0].plot(\n",
    "    distances,\n",
    "    linestyle=\"solid\",\n",
    "    marker=\"o\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "\n",
    "ax[0].set_xlabel(\"Sorted Index\")\n",
    "ax[0].set_ylabel(\"Average Distance\")\n",
    "\n",
    "sns.kdeplot(distances, shade=True, color=\"blue\", ax=ax[1])\n",
    "ax[1].set_xlabel(\"Average Distance\")\n",
    "\n",
    "fig.suptitle(\"K-Distance for %d Nearest Neighbors\" % min_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_start = 0.5\n",
    "eps_stop = 0.7\n",
    "num_eps_points = 21\n",
    "eps_list = np.linspace(eps_start, eps_stop, num_eps_points, endpoint=True)\n",
    "display(eps_list)\n",
    "\n",
    "n_clusters_list = []\n",
    "n_noise_list = []\n",
    "\n",
    "for eps in eps_list:\n",
    "    dbscan = cluster.DBSCAN(eps=eps, min_samples=min_samples).fit(X)\n",
    "    n_clusters_list.append(len(np.unique(dbscan.labels_[dbscan.labels_ != -1])))\n",
    "    n_noise_list.append(np.sum(dbscan.labels_ == -1))\n",
    "\n",
    "# for eps in eps_list:\n",
    "#     for min_samples in min_samples_list:\n",
    "#         dbscan = cluster.DBSCAN(eps=eps, min_samples=min_samples).fit(X)\n",
    "#         (unique_labels, counts) = np.unique(dbscan.labels_, return_counts=True)\n",
    "#         null_count = counts[unique_labels == -1][0] if -1 in unique_labels else 0\n",
    "#         null_pct = null_count / len(X) * 100.0\n",
    "#         non_null_pct = counts[unique_labels != -1] / len(X) * 100.0\n",
    "#         num_labels = np.sum(unique_labels != -1)\n",
    "#         if num_labels in [2, 3, 4, 5] and null_pct < 25.0 or 1:\n",
    "#             score = 0.0  # metrics.silhouette_score(X, dbscan.labels_)\n",
    "#             msg = (\n",
    "#                 \"eps = %.2f, min samples = %d, nulls = %d, %.2f%%, num labels = %d, score = %.2f, label distr = %s\"\n",
    "#                 % (\n",
    "#                     eps,\n",
    "#                     min_samples,\n",
    "#                     null_count,\n",
    "#                     null_pct,\n",
    "#                     num_labels,\n",
    "#                     score,\n",
    "#                     str(np.round(non_null_pct, 1)),\n",
    "#                 )\n",
    "#             )\n",
    "#             print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1_color = \"black\"\n",
    "ax1.plot(\n",
    "    eps_list,\n",
    "    n_clusters_list,\n",
    "    linestyle=\"solid\",\n",
    "    marker=\"o\",\n",
    "    color=ax1_color,\n",
    ")\n",
    "\n",
    "ax1.set_xlabel(\"Epsilon\")\n",
    "ax1.set_ylabel(\"Number of Clusters\")\n",
    "\n",
    "ax2_color = \"blue\"\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(\n",
    "    eps_list,\n",
    "    n_noise_list,\n",
    "    linestyle=\"solid\",\n",
    "    marker=\"o\",\n",
    "    color=ax2_color,\n",
    ")\n",
    "\n",
    "ax2.set_ylabel(\"Number of Noise Values\", color=ax2_color)\n",
    "ax2.tick_params(axis=\"y\", labelcolor=ax2_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = cluster.DBSCAN(eps=0.54, min_samples=min_samples).fit(X)\n",
    "(unique_labels, counts) = np.unique(dbscan.labels_, return_counts=True)\n",
    "display([unique_labels, counts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled[\"dbscan\"] = dbscan.labels_\n",
    "display(df_labeled.head())\n",
    "display(df_labeled.groupby(\"dbscan\").count().reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scatter_3d(df_labeled.query(\"dbscan != -1\"), color=\"dbscan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optics = cluster.OPTICS(min_samples=10).fit(X)\n",
    "# (unique_labels, counts) = np.unique(optics.labels_, return_counts=True)\n",
    "# display([unique_labels, counts])\n",
    "# optics.get_params(deep=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
